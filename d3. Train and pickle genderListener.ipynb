{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train genderListener and pickle it\n",
    "\n",
    "Purpose of this notebook:\n",
    "1. Upload dataset containing the metadata and audio features\n",
    "2. Create the model pipeline\n",
    "3. Train the model\n",
    "4. Pickle the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import common python library\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "# Import numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib import colors\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import scikit-learn library\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler,\n",
    "                                   LabelEncoder, \n",
    "                                   OneHotEncoder)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Import imbalance-learn library\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Import user created library\n",
    "#from code_cc import utilities\n",
    "import aux_code.functions as mfc\n",
    "from aux_code.utilities import *  # These are functions created by Emmanuel Contreras-Campana, Ph.D.\n",
    "\n",
    "# random seed\n",
    "seed = 3\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comments', 'description', 'duration', 'event', 'film_date',\n",
       "       'languages', 'main_speaker', 'name', 'num_speaker', 'published_date',\n",
       "       'ratings', 'related_talks', 'speaker_occupation', 'tags', 'title',\n",
       "       'url', 'views', 'link', 'annualTED', 'film_year', 'published_year',\n",
       "       'num_speaker_talks', 'technology', 'science', 'global issues',\n",
       "       'culture', 'design', 'business', 'entertainment', 'health',\n",
       "       'innovation', 'society', 'Fascinating', 'Courageous', 'Longwinded',\n",
       "       'Obnoxious', 'Jaw-dropping', 'Inspiring', 'OK', 'Beautiful', 'Funny',\n",
       "       'Unconvincing', 'Ingenious', 'Informative', 'Confusing', 'Persuasive',\n",
       "       'wpm', 'words_per_min', 'first_name', 'gender_name',\n",
       "       'gender_name_class', 'fileName', 'ZCR', 'Energy', 'EnergyEntropy',\n",
       "       'SpectralCentroid', 'SpectralSpread', 'SpectralEntropy', 'SpectralFlux',\n",
       "       'SpectralRollof', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfccC5', 'mfcc6',\n",
       "       'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13',\n",
       "       'Chroma1', 'Chroma2', 'Chroma3', 'Chroma4', 'Chroma5', 'Chroma6',\n",
       "       'Chroma7', 'Chroma8', 'Chroma9', 'Chroma10', 'Chroma11', 'Chroma12',\n",
       "       'Chroma_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload metadata\n",
    "df = pd.read_csv('data/meta_audio.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 34)\n",
      "male/female speakers Counter({0.0: 849, 1.0: 280})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZCR</th>\n",
       "      <th>Energy</th>\n",
       "      <th>EnergyEntropy</th>\n",
       "      <th>SpectralCentroid</th>\n",
       "      <th>SpectralSpread</th>\n",
       "      <th>SpectralEntropy</th>\n",
       "      <th>SpectralFlux</th>\n",
       "      <th>SpectralRollof</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>...</th>\n",
       "      <th>Chroma4</th>\n",
       "      <th>Chroma5</th>\n",
       "      <th>Chroma6</th>\n",
       "      <th>Chroma7</th>\n",
       "      <th>Chroma8</th>\n",
       "      <th>Chroma9</th>\n",
       "      <th>Chroma10</th>\n",
       "      <th>Chroma11</th>\n",
       "      <th>Chroma12</th>\n",
       "      <th>Chroma_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.157549</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>3.261160</td>\n",
       "      <td>0.236284</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>1.599764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246690</td>\n",
       "      <td>-11.097283</td>\n",
       "      <td>1.327426</td>\n",
       "      <td>...</td>\n",
       "      <td>1.599878e-09</td>\n",
       "      <td>2.665708e-09</td>\n",
       "      <td>1.376139e-09</td>\n",
       "      <td>7.381325e-09</td>\n",
       "      <td>1.894452e-09</td>\n",
       "      <td>2.329639e-09</td>\n",
       "      <td>4.507106e-09</td>\n",
       "      <td>1.057406e-08</td>\n",
       "      <td>1.167405e-08</td>\n",
       "      <td>3.479431e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111670</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>3.286377</td>\n",
       "      <td>0.182854</td>\n",
       "      <td>0.206212</td>\n",
       "      <td>0.828991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123830</td>\n",
       "      <td>-11.372760</td>\n",
       "      <td>2.260590</td>\n",
       "      <td>...</td>\n",
       "      <td>7.222366e-09</td>\n",
       "      <td>7.437066e-09</td>\n",
       "      <td>2.284307e-09</td>\n",
       "      <td>8.678086e-08</td>\n",
       "      <td>3.631717e-09</td>\n",
       "      <td>8.220817e-09</td>\n",
       "      <td>5.630347e-09</td>\n",
       "      <td>5.760660e-09</td>\n",
       "      <td>9.587197e-09</td>\n",
       "      <td>2.225379e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126741</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>3.319345</td>\n",
       "      <td>0.229218</td>\n",
       "      <td>0.235725</td>\n",
       "      <td>1.074359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179995</td>\n",
       "      <td>-11.518566</td>\n",
       "      <td>1.970373</td>\n",
       "      <td>...</td>\n",
       "      <td>4.655073e-09</td>\n",
       "      <td>1.070902e-08</td>\n",
       "      <td>7.810629e-09</td>\n",
       "      <td>1.046956e-08</td>\n",
       "      <td>6.754750e-09</td>\n",
       "      <td>3.192602e-09</td>\n",
       "      <td>5.348694e-09</td>\n",
       "      <td>8.367562e-09</td>\n",
       "      <td>6.860652e-09</td>\n",
       "      <td>3.030290e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ZCR    Energy  EnergyEntropy  SpectralCentroid  SpectralSpread  \\\n",
       "1  0.157549  0.012028       3.261160          0.236284        0.219008   \n",
       "3  0.111670  0.014973       3.286377          0.182854        0.206212   \n",
       "4  0.126741  0.011402       3.319345          0.229218        0.235725   \n",
       "\n",
       "   SpectralEntropy  SpectralFlux  SpectralRollof      mfcc1     mfcc2  \\\n",
       "1         1.599764           0.0        0.246690 -11.097283  1.327426   \n",
       "3         0.828991           0.0        0.123830 -11.372760  2.260590   \n",
       "4         1.074359           0.0        0.179995 -11.518566  1.970373   \n",
       "\n",
       "       ...            Chroma4       Chroma5       Chroma6       Chroma7  \\\n",
       "1      ...       1.599878e-09  2.665708e-09  1.376139e-09  7.381325e-09   \n",
       "3      ...       7.222366e-09  7.437066e-09  2.284307e-09  8.678086e-08   \n",
       "4      ...       4.655073e-09  1.070902e-08  7.810629e-09  1.046956e-08   \n",
       "\n",
       "        Chroma8       Chroma9      Chroma10      Chroma11      Chroma12  \\\n",
       "1  1.894452e-09  2.329639e-09  4.507106e-09  1.057406e-08  1.167405e-08   \n",
       "3  3.631717e-09  8.220817e-09  5.630347e-09  5.760660e-09  9.587197e-09   \n",
       "4  6.754750e-09  3.192602e-09  5.348694e-09  8.367562e-09  6.860652e-09   \n",
       "\n",
       "     Chroma_std  \n",
       "1  3.479431e-09  \n",
       "3  2.225379e-08  \n",
       "4  3.030290e-09  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model uses all 34 pyAudioAnalysis features\n",
    "audioCols = ['ZCR', 'Energy', 'EnergyEntropy',\n",
    "       'SpectralCentroid', 'SpectralSpread', 'SpectralEntropy', 'SpectralFlux',\n",
    "       'SpectralRollof', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfccC5', 'mfcc6',\n",
    "       'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13',\n",
    "       'Chroma1', 'Chroma2', 'Chroma3', 'Chroma4', 'Chroma5', 'Chroma6',\n",
    "       'Chroma7', 'Chroma8', 'Chroma9', 'Chroma10', 'Chroma11', 'Chroma12',\n",
    "       'Chroma_std']\n",
    "\n",
    "# The dataset from which our training and validation sets will come out should only include \n",
    "# the talks with 1 speaker and gender_name_class or 0 or 1.\n",
    "# Excluding talks with very low words_per_min (below 25th percentile) lets us exclude some musical performances\n",
    "df_model = df.loc[(df['num_speaker']==1) & (df['gender_name_class'].isin([0.0, 1,0])) & (df['words_per_min'] >=131), audioCols +['gender_name_class']]\n",
    "X = df_model[audioCols]\n",
    "print(X.shape)\n",
    "print('male/female speakers',Counter(df.loc[df['gender_name_class'].isin([0.0, 1,0]), 'gender_name_class']))\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = df_model['gender_name_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing \n",
    "I transform feature values to their z-scores, meaning every feature will have a mean of zero and a standard deviation of 1. This particular standardization method assumes that features have a normal distribution, which is true in this case. \n",
    "\n",
    "Standardizing makes it possible to:\n",
    "- compare the effect of different predictor variables\n",
    "- interpret the model parameters based on 'standard deviation' units of the predicted variables (and optionally of the predictor). [.](https://think-lab.github.io/d/205/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The StandardScaler assumes your data is normally distributed within each feature \n",
    "# and will output the z-scores.\n",
    "# The distribution is now centred around 0, with a standard deviation of 1.\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to produce gender labels\n",
    "\n",
    "There are about 3x as many talks by male speakers than by female speakers, that is to say that the male/female target classes are highly imbalanced. This affects model performance and some measures must be taken to mitigate the impact.\n",
    "\n",
    "In this case, I opt for oversampling the minority class to match the sample size of the majority class, using a method closely related to bootstrap sampling.\n",
    "\n",
    "The hyper-parameters will be optimized and cross-validated using the Logarithmic Loss function (i.e. log loss). Log loss was chosen because it heavily penalizes any strongly mis-classified predictions. \n",
    "\n",
    "Precision and Recall are used for the model selection and evaluation. To make sure that precision and recall are robust, I cross-validate them.\n",
    "\n",
    "I employ stratified k-fold cross validation instead of regular (non-stratified) k-fold cross-validation. In stratified k-fold cross validation, samples from each target class are chosen separately to ensure that each fold contains samples from both target classes. Using non-stratified k-fold cross validation on a highly dataset that has highly imbalanced target classes could result in some folds containing only samples from the majority class. \n",
    "\n",
    "To reduce computation time, I use 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stratified K-Fold cross-validation\n",
    "k_fold = 4\n",
    "\n",
    "outer_kfold_cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "inner_kfold_cv = StratifiedKFold(n_splits=k_fold-1, shuffle=True, random_state=seed)\n",
    "\n",
    "## Random Over Sampling of minority class\n",
    "ros = RandomOverSampler(ratio='all', random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary to store all the model performance scores\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear model with good interpretability. Linear models are great at indicating the relative importance (predictive power) of different features. I use ridge regression with different regularization parameters to find the ones that most improve the model performance.\n",
    "\n",
    "- ridge regression\n",
    "    - uses L2 regularization technique\n",
    "    - prevent multicollinearity by reducing the model parameters\n",
    "    - reduces the model complexity by preveting extremely large coefficients\n",
    "    - has hyperparameter alpha, which controls the penalty term. Higher values of alpha can help reduce the magnitude of coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SciPy's pipeline constructor make_pipeline [doc](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fitting a logistic regression model with ridge regression\n",
    "\n",
    "# Create a parameter grid for hyper-parameter optimization using grid_search\n",
    "name = 'LogisticRegression'.lower()\n",
    "param_grid = {name+'__C': [0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Losgistic regression model\n",
    "# using multi-class version because later I will have more just the \"Male\" and \"Female\" classes\n",
    "# sag: the Stochastic Average Gradient Descent solver is fast for large datasets, compatible for multi-class problems, and compatible with ridge regression, \n",
    "# penalty: the norm used in the penalization. The â€˜sagâ€™ solver supports only l2 penalties.\n",
    "# C: Inverse of regularization strength; must be a positive float. Smaller values specify stronger regularization.\n",
    "log = LogisticRegression(penalty='l2', C=0.1, \n",
    "                         solver='sag', #'liblinear', #'lbfgs', #'sag',\n",
    "                         max_iter=1000, n_jobs=-1,\n",
    "                         tol= 1e-3,\n",
    "                         class_weight=None,\n",
    "                         multi_class='multinomial')\n",
    "\n",
    "#Construct a Pipeline from the given estimators.\n",
    "# ros: Random Over Sampling of minority class\n",
    "# scaler: Scale features to their z-scores\n",
    "# log: logistic regression model\n",
    "\n",
    "pipe = make_pipeline(ros, scaler, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter optimization and model evaluation using nested cross-validation\n",
    "\n",
    "A hyper-parameter grid search consists of:\n",
    "\n",
    "- an estimator (regressor or classifier such as LogisticRegression());\n",
    "- a parameter space;\n",
    "- a method for searching or sampling candidates;\n",
    "- a cross-validation scheme such as k-fold cross validation; and\n",
    "- a score function such as neg_log_loss. [SciPy](http://scikit-learn.org/stable/modules/grid_search.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carry out a grid search to find the parameter values that give \n",
    "# the lowest log-loss using stratified k-fold cross-validation.\n",
    "# grid_search is a user-created function in utilities.py\n",
    "log = grid_search(pipe, X, y,\n",
    "                  outer_kfold_cv, inner_kfold_cv,\n",
    "                  param_grid, scoring='neg_log_loss', \n",
    "                  debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the trained model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist model : After training a scikit-learn model, it is desirable to \n",
    "# have a way to persist the model for future use without having to retrain.\n",
    "# joblib.dump: joblibâ€™s replacement of pickle, which is more \n",
    "# efficient on objects that carry large numpy arrays internally as is often \n",
    "# the case for fitted scikit-learn estimators\n",
    "joblib.dump(log, 'models/genderListener.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Final model evaluation is 0.34 (i.e. the log loss).\n",
    "\n",
    "The cross-validated precision scoresfor the \"Male\" and \"Female\" classes is 96% and 78%. The cross-validated recall scores are 90% and 89%. F-score is the harmonic mean of precision and recall.\n",
    "\n",
    "It was expected that the performance for the minority class (\"Female\") would be lower because there are 3 times fewer unique \"female\" samples. While random oversampling helped mitigate the class imbalance problem, the performance difference classifying 'male' and 'female' is still noticeable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
